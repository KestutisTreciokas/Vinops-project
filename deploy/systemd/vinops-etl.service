[Unit]
Description=Vinops ETL Service - Fresh CSV Ingestion
After=network.target docker.service
Wants=network-online.target

[Service]
Type=oneshot
User=root
WorkingDirectory=/root/Vinops-project
Environment="NODE_OPTIONS=--experimental-default-type=module --max-old-space-size=4096"
Environment="DATABASE_URL=postgresql://gen_user:J4nm7NGq^Rn5pH@192.168.0.5:5432/vinops_db"
Environment="R2_ENDPOINT=https://38501dfb36ea4ff432ff93ace1b04705.r2.cloudflarestorage.com"
Environment="R2_ACCESS_KEY_ID=3b60a2ba2fdcc4a118f245bedd98b411"
Environment="R2_SECRET_ACCESS_KEY=882639ba38b7075df8463bf1a7676c81d806051beb15eb286b6d4bdbd3192174"
Environment="R2_BUCKET_NAME=vinops-prod"
Environment="PGSSL_DISABLE=1"

# Resource limits
MemoryMax=6G
CPUQuota=150%
TasksMax=500
TimeoutStopSec=30s

# Download CSV, ingest to staging, upsert to public lots, download images for NEW lots only
ExecStart=/bin/bash -c '\
  CSV_DIR=/var/data/vinops/raw/copart/$(date +%%Y/%%m/%%d) && \
  mkdir -p $CSV_DIR && \
  CSV_FILE=$CSV_DIR/$(date +%%H%%M).csv && \
  echo "[ETL] Downloading CSV from Copart..." && \
  curl -L -o $CSV_FILE "https://inventory.copart.io/FTPLSTDM/salesdata.cgi?authKey=YPYU91EI" && \
  echo "[ETL] Ingesting CSV to staging..." && \
  node scripts/ingest-copart-csv.js $CSV_FILE && \
  echo "[ETL] Upserting lots to public schema..." && \
  node scripts/upsert-lots.js && \
  echo "[ETL] Downloading images for NEW lots (last 24 hours)..." && \
  node scripts/ingest-images-from-staging.js --limit=5000 --batch-size=100 --concurrency=20'

# Logging
StandardOutput=append:/var/log/vinops/etl.log
StandardError=append:/var/log/vinops/etl-error.log
SyslogIdentifier=vinops-etl
